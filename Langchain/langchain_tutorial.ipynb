{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1a28597-514e-48af-b887-f67ea28b7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Langchain Tutorial\n",
    "# import openai\n",
    "# import os\n",
    "#  Here is the ai\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# # llm = OpenAI(temperature=0.3)\n",
    "# # print(llm.predict(\"what is the population of the india\"))\n",
    "\n",
    "# #  Prompt template..\n",
    "# # country = \"India\"\n",
    "# # prompt = PromptTemplate.from_template(\"What is the capital of the {country}?\")\n",
    "# # print(prompt)\n",
    "\n",
    "# #  Perform the task with langchain by using the LLM Chain\n",
    "# # cities = [\"mumbai\", \"uttar pradesh\", \"gujarat\", \"rajasthan\"]\n",
    "# # prompt = PromptTemplate.from_template(\"what is the capital of {place}\")\n",
    "# # llm = OpenAI(temperature=0.3)\n",
    "\n",
    "# # chain = LLMChain(llm = llm, prompt = prompt)\n",
    "# # for i in cities:\n",
    "# #     output = chain.run(i)\n",
    "# #     print(output)\n",
    "# #     import time\n",
    "# #     time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd901e47-7cf2-464c-b8ae-185fe277db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "There are many e-commerce stores that sell candles, so it is not possible to provide a specific name. Some popular online candle stores include Yankee Candle, Bath & Body Works, and Diptyque.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m Each store will have its own unique product names for their candles. \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Each store will have its own unique product names for their candles. \n"
     ]
    }
   ],
   "source": [
    "# #  LLM to get name of an ecommerce store from a product name..\n",
    "# prompt = PromptTemplate.from_template(\"What is the name of the e commerce store that sells {product}?\")\n",
    "# llm = OpenAI(temperature = 0.3)\n",
    "# chain1 = LLMChain(llm = llm, prompt = prompt)\n",
    "# # product = \"iphone\"\n",
    "# # output = chain.run(product)\n",
    "# # print(output)\n",
    "\n",
    "# # LLM to get comma separated name of products from an e commerce store name\n",
    "# prompt = PromptTemplate.from_template(\"What is the name of the products at {store}\")\n",
    "# llm = OpenAI(temperature = 0.3)\n",
    "# chain2 = LLMChain(llm = llm, prompt = prompt)\n",
    "\n",
    "# # Create an overall chain from simple sequential chain\n",
    "# chain = SimpleSequentialChain(\n",
    "#     chains = [chain1, chain2],\n",
    "#     verbose=True\n",
    "#     # input_variables = [\"product\", \"store\"]\n",
    "# )\n",
    "# output = chain.run(\"candles\")\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a5822-6b62-47a2-af7a-942b0f92390d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08683740-1fe3-4a3a-987a-441b9dfe420e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5087e3f-f4a6-4774-97ab-1ad918b1d5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b8881-edb8-4ce1-b420-44906f645c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14746239-b933-49f8-840f-e59c19285538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab3f76-1165-408c-991d-13a2e00a810b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d93eb-d77d-47c4-996f-e560e4631bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48054631-6209-4439-b729-e47b9657ecde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3318-14d3-4b8e-a0c9-f4e29d93f85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7e59c-cd66-44a1-b84b-5ac634722498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce344e-50bf-40b2-ae7b-6bac9b0bf662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
